โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
๐ง FIX OLLAMA 500 ERROR - EXECUTAR AGORA
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

PROBLEMA: Ollama retorna 500 porque modelo llama2 nรฃo estรก baixado

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
๐ SOLUรรO 1: BAIXAR MODELO LLAMA2 (RECOMENDADO SE TEM ESPAรO)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

# 1. Verificar se modelo estรก baixado
docker compose exec ollama ollama list

# Se retornar vazio ou nรฃo mostrar llama2:

# 2. Baixar modelo llama2 (~4GB, demora 5-10 min)
docker compose exec ollama ollama pull llama2

# 3. Aguardar download completar e verificar
docker compose exec ollama ollama list

# Deve mostrar:
# NAME            ID              SIZE    MODIFIED
# llama2:latest   78e26419b446    3.8 GB  X minutes ago

# 4. Testar Ollama diretamente
docker compose exec ollama ollama run llama2 "Hello, how are you?"

# 5. Testar API
curl -X POST http://localhost:8000/analyze \
  -H 'Content-Type: application/json' \
  -d '{"regulatory_text":"RESOLUรรO BCB Nยบ 789/2024","repo_path":"/app/fake_pix_repo"}'

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
๐ SOLUรรO 2: USAR GEMINI (MAIS RรPIDO, SEM DOWNLOAD)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

Se nรฃo tem espaรงo ou quer algo mais rรกpido:

# 1. Parar containers
cd ~/poc_multiagent_lang
docker compose down

# 2. Editar .env
nano .env

# Apagar estas linhas:
LLM_TYPE=ollama
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_MODEL=llama2

# Adicionar estas linhas:
LLM_TYPE=gemini
GEMINI_API_KEY=AIzaSyBVk3MFe3zRRGVMaEslphM3Vd85oS5Rz44
GEMINI_MODEL=gemini-2.0-flash

# Salvar: Ctrl+O, Enter, Ctrl+X

# 3. Subir apenas serviรงos necessรกrios (sem Ollama)
docker compose up -d postgres backend frontend

# 4. Ver logs
docker compose logs -f backend

# 5. Testar (deve ser MUITO mais rรกpido)
curl -X POST http://localhost:8000/analyze \
  -H 'Content-Type: application/json' \
  -d '{"regulatory_text":"RESOLUรรO BCB Nยบ 789/2024","repo_path":"/app/fake_pix_repo"}'

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โก COMPARAรรO DE PERFORMANCE
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

OLLAMA (llama2 local):
  โฑ๏ธ  Tempo por request: 60-120 segundos
  ๐พ Espaรงo em disco: ~4GB
  ๐ง RAM necessรกria: ~2-4GB
  ๐ฆ Setup: Precisa baixar modelo
  ๐ฐ Custo: Grรกtis
  ๐ Privacidade: Total (dados nรฃo saem do servidor)

GEMINI (API):
  โฑ๏ธ  Tempo por request: 2-5 segundos (20x mais rรกpido!)
  ๐พ Espaรงo em disco: 0
  ๐ง RAM necessรกria: 0
  ๐ฆ Setup: Apenas API key
  ๐ฐ Custo: Grรกtis (com limites generosos)
  ๐ Privacidade: Dados vรฃo para Google

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
๐ก RECOMENDAรรO
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

Para POC/Testes: USE GEMINI
  โ 20x mais rรกpido
  โ Sem problemas de espaรงo
  โ Sem download
  โ Melhor qualidade de resposta

Para Produรงรฃo com dados sensรญveis: USE OLLAMA
  โ Privacidade total
  โ Sem custos de API
  โ Precisa servidor maior (t3.medium+)
  โ Muito mais lento

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
๐ VERIFICAR ESPAรO DISPONรVEL
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

# Ver espaรงo em disco
df -h

# Se tiver menos de 5GB livres, use GEMINI
# Se tiver mais de 5GB livres, pode usar OLLAMA

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ QUAL ESCOLHER?
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

Escolha GEMINI se:
  - Quer testar rรกpido
  - Tem pouco espaรงo em disco (<5GB livre)
  - Quer respostas mais rรกpidas
  - Nรฃo tem dados super sensรญveis

Escolha OLLAMA se:
  - Tem dados muito sensรญveis
  - Tem espaรงo em disco (>5GB livre)
  - Pode esperar 60s+ por resposta
  - Quer evitar custos de API no futuro
