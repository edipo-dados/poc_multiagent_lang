#!/bin/bash

echo "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ"
echo "โ  ๐ฅ Baixando modelo llama2 no Ollama Docker                  โ"
echo "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ"
echo ""

echo "โณ Iniciando download do modelo llama2 (3.8GB)..."
echo "   Isso pode demorar alguns minutos dependendo da conexรฃo."
echo ""

docker compose exec ollama ollama pull llama2

if [ $? -eq 0 ]; then
    echo ""
    echo "โ Modelo llama2 baixado com sucesso!"
    echo ""
    echo "Verificando modelos instalados:"
    docker compose exec ollama ollama list
    echo ""
    echo "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ"
    echo "โ  ๐ PRONTO! Agora vocรช pode testar a API                     โ"
    echo "โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ"
    echo ""
    echo "Teste com:"
    echo "curl -X POST http://localhost:8000/analyze \\"
    echo "  -H 'Content-Type: application/json' \\"
    echo "  -d '{\"regulatory_text\":\"RESOLUรรO BCB Nยบ 789/2024\",\"repo_path\":\"/app/fake_pix_repo\"}'"
else
    echo ""
    echo "โ Erro ao baixar modelo!"
    echo ""
    echo "Verifique:"
    echo "1. Container Ollama estรก rodando: docker compose ps"
    echo "2. Logs do Ollama: docker compose logs ollama"
    echo "3. DNS funcionando: docker compose exec ollama ping -c 2 registry.ollama.ai"
fi
