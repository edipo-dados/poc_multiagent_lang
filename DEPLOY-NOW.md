# üöÄ Deploy Agora - Instru√ß√µes R√°pidas

## O Que Foi Corrigido

‚úÖ Conex√£o do Ollama do container Docker para o host EC2
‚úÖ Vari√°vel de ambiente correta (`LLM_TYPE` ao inv√©s de `LLM_PROVIDER`)
‚úÖ URL do banco de dados correta para containers Docker
‚úÖ Configura√ß√£o do `docker-compose.yml` com `extra_hosts`

---

## Comandos para Executar no EC2

### 1. Fazer Pull das Mudan√ßas
```bash
cd ~/poc_multiagent_lang
git pull origin main
```

### 2. Executar o Script de Fix
```bash
bash quick-fix-deploy.sh
```

**O script vai:**
- ‚úÖ Atualizar o `.env` com as configura√ß√µes corretas
- ‚úÖ Atualizar o `docker-compose.yml` (com backup)
- ‚úÖ Reiniciar o backend
- ‚úÖ Verificar o status
- ‚úÖ Mostrar os logs

### 3. Verificar se Funcionou
```bash
# Ver os logs (N√ÉO deve ter "Connection refused")
docker compose logs backend --tail 50 | grep -i ollama

# Testar a API
curl -X POST http://localhost:8000/analyze \
  -H 'Content-Type: application/json' \
  -d '{
    "regulatory_text": "RESOLU√á√ÉO BCB N¬∫ 789/2024 - Teste",
    "repo_path": "/app/fake_pix_repo"
  }'
```

---

## O Que Esperar

### Antes do Fix ‚ùå
```
Ollama API call failed: Connection refused
Translator Agent: Using fallback
```

### Depois do Fix ‚úÖ
```
Initialized OllamaLLM with model=llama2, base_url=http://host.docker.internal:11434
Translator Agent completed successfully
```

---

## Se Algo Der Errado

### Op√ß√£o 1: Ver Logs Detalhados
```bash
docker compose logs backend -f
```

### Op√ß√£o 2: Verificar Ollama no Host
```bash
curl http://localhost:11434/api/tags
```

### Op√ß√£o 3: Testar Conex√£o do Container
```bash
docker compose exec backend ping -c 2 host.docker.internal
```

### Op√ß√£o 4: Consultar Troubleshooting
```bash
cat TROUBLESHOOTING.md
```

---

## Pr√≥ximos Passos Ap√≥s o Fix

1. **Popular Embeddings** (para CodeReader funcionar):
   ```bash
   docker compose exec backend python -m backend.scripts.populate_embeddings_sync
   ```

2. **Testar Pipeline Completo**:
   ```bash
   curl -X POST http://localhost:8000/analyze \
     -H 'Content-Type: application/json' \
     -d '{
       "regulatory_text": "RESOLU√á√ÉO BCB N¬∫ 789/2024...",
       "repo_path": "/app/fake_pix_repo"
     }' | jq '.'
   ```

3. **Acessar Frontend**:
   ```
   http://SEU_IP_EC2:8501
   ```

---

## Resumo dos Arquivos Modificados

- `.env.example` - Template atualizado com configura√ß√µes corretas
- `docker-compose.yml` - Adicionado `extra_hosts` para acesso ao host
- `quick-fix-deploy.sh` - Script autom√°tico de deploy
- `fix-ollama-connection.sh` - Script alternativo
- `TROUBLESHOOTING.md` - Guia completo de troubleshooting
- `FIX-SUMMARY.md` - Resumo detalhado do fix

---

## Comandos √öteis

```bash
# Reiniciar tudo
docker compose restart

# Ver status
docker compose ps

# Ver logs em tempo real
docker compose logs -f

# Health check
curl http://localhost:8000/health | jq '.'

# Parar tudo
docker compose down

# Rebuild completo (se necess√°rio)
docker compose up -d --build
```

---

## ‚ö†Ô∏è IMPORTANTE: Revogue sua API Key do OpenAI

Voc√™ exp√¥s sua chave OpenAI v√°rias vezes na conversa:
```
sk-proj-k1DSxrKn8UGV...
```

**A√á√ÉO NECESS√ÅRIA:**
1. Acesse: https://platform.openai.com/api-keys
2. Revogue a chave exposta
3. Crie uma nova chave se precisar usar OpenAI no futuro

Por enquanto, estamos usando Ollama (local), ent√£o n√£o precisa da chave OpenAI.

---

## Contato R√°pido

Se tiver problemas:
1. Verifique os logs: `docker compose logs backend --tail 100`
2. Consulte: `TROUBLESHOOTING.md`
3. Verifique: `FIX-SUMMARY.md`
