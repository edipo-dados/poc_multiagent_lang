# Database Configuration
# IMPORTANT: Use different URLs depending on where you're connecting from:
# - Inside Docker container: use service name 'postgres' and port 5432
# - From host machine: use 'localhost' and port 5433 (mapped port)

# For Docker containers (backend service):
DATABASE_URL=postgresql+asyncpg://postgres:postgres@postgres:5432/regulatory_ai

# For host machine (local development):
# DATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost:5433/regulatory_ai

# For SQLite (development without PostgreSQL):
# DATABASE_URL=sqlite+aiosqlite:///./regulatory_ai.db

# LLM Configuration
# IMPORTANT: LLM_TYPE not LLM_PROVIDER (code uses LLM_TYPE)
# Options: ollama, openai, local
LLM_TYPE=ollama

# ============================================================================
# OLLAMA Configuration (if LLM_TYPE=ollama)
# ============================================================================
# IMPORTANT: Use different URLs depending on where you're connecting from:
# - Inside Docker container: use host IP or 'host.docker.internal'
# - From host machine: use 'localhost'

# For Docker containers (backend service):
OLLAMA_BASE_URL=http://host.docker.internal:11434

# For host machine (local development):
# OLLAMA_BASE_URL=http://localhost:11434

OLLAMA_MODEL=llama2

# ============================================================================
# OPENAI Configuration (if LLM_TYPE=openai)
# ============================================================================
# Get your API key from: https://platform.openai.com/api-keys
# OPENAI_API_KEY=sk-proj-...your-key-here...
# OPENAI_MODEL=gpt-3.5-turbo
# OPENAI_BASE_URL=https://api.openai.com/v1

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
