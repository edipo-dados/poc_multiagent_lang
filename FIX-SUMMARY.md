# ðŸ”§ Fix Summary - Ollama Connection Issue

## Problema Identificado

O Translator Agent estava falhando com erro de conexÃ£o:
```
Ollama API call failed: HTTPConnectionPool(host='localhost', port=11434): 
Connection refused
```

**Causa Raiz:** O container Docker tentava conectar em `localhost:11434`, mas o Ollama estÃ¡ rodando no host EC2, nÃ£o dentro do container.

---

## SoluÃ§Ã£o Implementada

### MudanÃ§as nos Arquivos

#### 1. `.env` - Atualizado
```env
DATABASE_URL=postgresql+asyncpg://postgres:postgres@postgres:5432/regulatory_ai
LLM_TYPE=ollama
OLLAMA_BASE_URL=http://host.docker.internal:11434
OLLAMA_MODEL=llama2
```

**MudanÃ§as:**
- âœ… `DATABASE_URL`: Mudou de `localhost:5433` para `postgres:5432` (nome do serviÃ§o Docker)
- âœ… `LLM_TYPE`: Corrigido de `LLM_PROVIDER` para `LLM_TYPE` (nome correto da variÃ¡vel)
- âœ… `OLLAMA_BASE_URL`: Mudou de `localhost:11434` para `host.docker.internal:11434`

#### 2. `docker-compose.yml` - Adicionado `extra_hosts`
```yaml
backend:
  extra_hosts:
    - "host.docker.internal:host-gateway"
```

Isso permite que o container acesse o host usando `host.docker.internal`.

---

## Como Aplicar o Fix no EC2

### OpÃ§Ã£o 1: Script AutomÃ¡tico (Recomendado)
```bash
# No seu EC2, no diretÃ³rio do projeto
bash quick-fix-deploy.sh
```

Este script vai:
1. âœ… Atualizar o `.env`
2. âœ… Atualizar o `docker-compose.yml` (com backup)
3. âœ… Reiniciar o backend
4. âœ… Verificar o status
5. âœ… Mostrar os logs

### OpÃ§Ã£o 2: Manual

```bash
# 1. Atualizar .env
cat > .env << 'EOF'
DATABASE_URL=postgresql+asyncpg://postgres:postgres@postgres:5432/regulatory_ai
LLM_TYPE=ollama
OLLAMA_BASE_URL=http://host.docker.internal:11434
OLLAMA_MODEL=llama2
EOF

# 2. Fazer backup do docker-compose.yml
cp docker-compose.yml docker-compose.yml.backup

# 3. Baixar o novo docker-compose.yml do repositÃ³rio
# (ou editar manualmente para adicionar extra_hosts no serviÃ§o backend)

# 4. Reiniciar o backend
docker compose restart backend

# 5. Verificar
curl http://localhost:8000/health
docker compose logs backend --tail 50
```

---

## VerificaÃ§Ã£o do Fix

### 1. Health Check
```bash
curl http://localhost:8000/health | jq '.'
```

**Esperado:**
```json
{
  "status": "healthy",
  "database": "connected",
  "vector_store": "available",
  "timestamp": "..."
}
```

### 2. Logs do Backend
```bash
docker compose logs backend --tail 50 | grep -i ollama
```

**Esperado:** NÃƒO deve aparecer "Connection refused"

**Deve aparecer:**
```
Initialized OllamaLLM with model=llama2, base_url=http://host.docker.internal:11434
Translator Agent completed successfully
```

### 3. Teste Completo da API
```bash
curl -X POST http://localhost:8000/analyze \
  -H 'Content-Type: application/json' \
  -d '{
    "regulatory_text": "RESOLUÃ‡ÃƒO BCB NÂº 789/2024 - Teste de regulaÃ§Ã£o",
    "repo_path": "/app/fake_pix_repo"
  }' | jq '.'
```

**Esperado:** Resposta JSON com anÃ¡lise completa, sem erros de conexÃ£o.

---

## Status dos Agentes ApÃ³s o Fix

| Agente | Status | ObservaÃ§Ã£o |
|--------|--------|------------|
| Sentinel | âœ… Funcionando | Detecta mudanÃ§as e avalia risco |
| Translator | âœ… Funcionando | Conecta ao Ollama via host.docker.internal |
| CodeReader | âš ï¸ TemporÃ¡rio | Retorna lista vazia (precisa popular embeddings) |
| Impact | âš ï¸ Limitado | Funciona mas sem arquivos do CodeReader |
| SpecGenerator | âœ… Funcionando | Gera spec mÃ­nima |
| KiroPrompt | âœ… Funcionando | Gera prompt mÃ­nimo |

---

## PrÃ³ximos Passos

### 1. Popular Embeddings (Para CodeReader funcionar)
```bash
docker compose exec backend python -m backend.scripts.populate_embeddings_sync
```

### 2. Testar Pipeline Completo
```bash
# Teste com texto regulatÃ³rio real
curl -X POST http://localhost:8000/analyze \
  -H 'Content-Type: application/json' \
  -d @test_payload.json
```

### 3. Monitorar Performance
```bash
# Logs em tempo real
docker compose logs backend -f

# Uso de recursos
docker stats
```

---

## Troubleshooting

Se ainda tiver problemas, consulte: `TROUBLESHOOTING.md`

### VerificaÃ§Ãµes RÃ¡pidas

1. **Ollama estÃ¡ rodando no host?**
   ```bash
   curl http://localhost:11434/api/tags
   ```

2. **Container consegue alcanÃ§ar o host?**
   ```bash
   docker compose exec backend ping -c 2 host.docker.internal
   ```

3. **VariÃ¡veis de ambiente corretas?**
   ```bash
   docker compose exec backend env | grep -E "(LLM|OLLAMA|DATABASE)"
   ```

---

## Arquivos Criados/Atualizados

- âœ… `.env` - ConfiguraÃ§Ã£o corrigida
- âœ… `docker-compose.yml` - Adicionado extra_hosts
- âœ… `quick-fix-deploy.sh` - Script de deploy automÃ¡tico
- âœ… `fix-ollama-connection.sh` - Script alternativo
- âœ… `TROUBLESHOOTING.md` - Guia completo de troubleshooting
- âœ… `FIX-SUMMARY.md` - Este arquivo

---

## Comandos Ãšteis

```bash
# Reiniciar tudo
docker compose restart

# Rebuild se necessÃ¡rio
docker compose up -d --build backend

# Ver logs de todos os serviÃ§os
docker compose logs -f

# Parar tudo
docker compose down

# Limpar e recomeÃ§ar
docker compose down -v
docker compose up -d
```
