โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ  ๐ TROCAR PARA OPENAI - Simples e Rรกpido                    โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

Como o cรณdigo estรก montado como volume, sรณ precisa atualizar .env e reiniciar.

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
๐ COMANDOS (copie tudo de uma vez)
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

# 1. Ver .env atual
echo "โโโ .env ATUAL โโโ"
cat .env
echo ""

# 2. Atualizar .env para OpenAI
cat > .env << 'EOF'
DATABASE_URL=postgresql+asyncpg://postgres:postgres@postgres:5432/regulatory_ai
LLM_TYPE=openai
OPENAI_API_KEY=SUA_CHAVE_AQUI
OPENAI_MODEL=gpt-3.5-turbo
EOF

# IMPORTANTE: Substitua SUA_CHAVE_AQUI pela sua chave real!

# 3. Verificar novo .env
echo "โโโ .env NOVO โโโ"
cat .env
echo ""

# 4. Reiniciar backend
docker compose restart backend

# 5. Aguardar
echo "Aguardando 10 segundos..."
sleep 10

# 6. Verificar variรกveis de ambiente do container
echo "โโโ VARIรVEIS NO CONTAINER โโโ"
docker compose exec backend env | grep -E "(LLM_TYPE|OPENAI)"
echo ""

# 7. Ver logs recentes
echo "โโโ LOGS RECENTES โโโ"
docker compose logs backend --tail 20 | grep -E "(LLM|OpenAI|Ollama)"
echo ""

# 8. Testar API
echo "โโโ TESTE DA API โโโ"
curl -X POST http://localhost:8000/analyze \
  -H 'Content-Type: application/json' \
  -d '{"regulatory_text":"RESOLUรรO BCB Nยบ 789/2024 - Teste","repo_path":"/app/fake_pix_repo"}' \
  2>&1 | head -20

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

COPIE TODO O BLOCO ACIMA

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ O QUE VOCร DEVE VER
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

No passo 6 (variรกveis):
LLM_TYPE=openai
OPENAI_API_KEY=sk-proj-...
OPENAI_MODEL=gpt-3.5-turbo

No passo 7 (logs):
"Initialized OpenAILLM with model=gpt-3.5-turbo"

No passo 8 (teste):
Resposta JSON em 2-5 segundos (nรฃo 60s!)

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ SE AINDA MOSTRAR OLLAMA
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

Problema: O .env nรฃo estรก sendo lido pelo container

Soluรงรฃo 1 - Parar e iniciar (nรฃo sรณ restart):
docker compose down
docker compose up -d
sleep 10
docker compose logs backend --tail 30

Soluรงรฃo 2 - Verificar se .env estรก no lugar certo:
pwd
ls -la .env
# Deve estar em ~/poc_multiagent_lang/.env

Soluรงรฃo 3 - Definir variรกveis direto no docker-compose.yml:
# Editar docker-compose.yml e adicionar em backend > environment:
  LLM_TYPE: openai
  OPENAI_API_KEY: sua-chave
  OPENAI_MODEL: gpt-3.5-turbo

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
๐ DEBUG: Ver o que o container estรก lendo
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

# Ver TODAS as variรกveis de ambiente
docker compose exec backend env | sort

# Ver especificamente LLM
docker compose exec backend python -c "import os; print('LLM_TYPE:', os.getenv('LLM_TYPE')); print('OPENAI_API_KEY:', os.getenv('OPENAI_API_KEY', 'NOT SET')[:20]+'...')"

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
